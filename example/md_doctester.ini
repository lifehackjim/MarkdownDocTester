
[CONFIG]
mainheader: Markdown Doc Tester Readme
output_blocks: true
valid_blocks: true
basename: md_doctester_readme
contact: Jim Olsen <jim@lifehack.com>

[Markdown Doc Tester Usage]
headerdepth: 1
cmd: md_doctester.py -h
validtests: exitcode

[Reason for MDT]
headerdepth: 1
norun: true
notes1: [Readme Driven Development](http://tom.preston-werner.com/2010/08/23/readme-driven-development.html)
notes2: I wanted a quick and simple way to create documentation for the myriad of scripts I write during the course of my work.
notes3: I wanted documentation in both HTML and markdown format.
notes4: I also wanted to be able to test my scripts in a consistent manner.

[Examples]
headerdepth: 1
norun: true
notes1: This readme was generated with MDT, for one example.
notes2: See [example/md_doctester.ini](example/md_doctester.ini) for how this README was generated
notes3: See [example/build.sh](example/build.sh) for a script that will build markdown and HTML documentation for all *.ini files in example/

[Adding notes]
headerdepth: 2
norun: true
notes1: Just include a definition that starts with 'notes'
notes2: You can define multiple notes, they just need to be named differently (but all must start with 'notes')

[Displaying an example command but not running it]
headerdepth: 2
norun: true
notes1: If you include a definition that contains 'norun: true', the command will not be run, just displayed in a bash code block
cmd: example_command -a -b -c 'FILENAME' -u "$USER"

[Running a command]
headerdepth: 2
notes1: Just include a definition 'cmd' with command you wish to run
cmd: uname -a

[Running a command and checking the exit code is 0]
headerdepth: 2
notes1: If you include a definition 'validtests' and specify 'exitcode' as one of the tests, it will by default check to see if the command exits with an exitcode of 0
notes2: If you include a definition 'exitcode' and specify an exitcode, it will check for that exit code instead of 0
cmd: python -V
validtests: exitcode

[Running a command and checking the exit code is NOT 0]
headerdepth: 2
notes1: If you include a definition 'validtests' and specify 'notexitcode' as one of the tests, it will by default check to see if the command exits with an exitcode that is NOT 0
notes2: If you include a definition 'exitcode' and specify an exitcode, it will check for that exit code instead of 0
exitcode: 5
cmd: python -V
validtests: notexitcode

[Checking that a file exists after running a command]
headerdepth: 2
notes1: If you include a definition 'validtests' and specify 'file_exist' as one of the tests, it will check that the file defined in 'file_exist' is found after running 'cmd'
file_exist: /tmp/foo/test
cmd: mkdir -p /tmp/foo && echo "this is a test" >> /tmp/foo/test && find /tmp/foo -ls
validtests: exitcode, file_exist

[Checking that a file match is found after running a command]
headerdepth: 2
notes1: If you include a definition 'validtests' and specify 'filematch' as one of the tests, it will check that the wildcard defined in 'filematch' is found somewhere under the directory defined in 'dirmatch'
filematch: *test*
dirmatch: /tmp
cmd: mkdir -p /tmp/foo && echo "this is a test" >> /tmp/foo/test && find /tmp/foo -ls
validtests: exitcode, filematch

[Checking that a file match is NOT found after running a command]
headerdepth: 2
notes1: If you include a definition 'validtests' and specify 'nofilematch' as one of the tests, it will check that the wildcard defined in 'filematch' is NOT found somewhere under the directory defined in 'dirmatch'
filematch: *test4*
dirmatch: /tmp
cmd: mkdir -p /tmp/foo && echo "this is a test" >> /tmp/foo/test && find /tmp/foo -ls
validtests: exitcode, nofilematch

[Performing cleanup BEFORE running a command]
headerdepth: 2
notes1: If you include a definition 'precleanup', the command specified there-in will be run before 'cmd' is run
notes2: This section has a precleanup with `rm -rf /tmp/foo`
precleanup: rm -rf /tmp/foo/
cmd: mkdir -p /tmp/foo && echo "this is a test" >> /tmp/foo/test && find /tmp/foo -ls
validtests: exitcode

[Creating Content BEFORE running a command]
headerdepth: 2
notes1: You can create content by defining 'contentfilenameN', 'contenttypeN', and 'contenttextN', where N is the same for each definition. For example:
notes2: `contentfilename1: /tmp/foo/test.json`
notes3: `contenttype1: json`
notes4: `contenttext1: { "test": "blah" }`
notes5: this would create a file in /tmp/foo/test.json before running 'cmd'. when displaying the content block, contenttype will be added into the code fencing blocks
precleanup: rm -rf /tmp/foo
contentfilename1: /tmp/foo/test.json
contenttype1: json
contenttext1: {
    "test": "blah"
    }
cmd: find /tmp/foo -ls
file_exist: /tmp/foo/test.json
validtests: exitcode, file_exist

[Showing Content AFTER running a command]
headerdepth: 2
notes1: You can show content after a command is run by defining 'afterfilenameN' and 'aftertypeN', and 'contenttextN', where N is the same for each definition. For example:
notes2: `afterfilename1: /tmp/foo/test.json`
notes3: `aftertype1: json`
notes4: This would show the contents of the file/tmp/foo/test.json after running 'cmd'. when displaying the content block, aftertype will be added into the code fencing blocks
precleanup: rm -rf /tmp/foo
cmd: mkdir -p /tmp/foo && echo '{ "test": "blah" }' > /tmp/foo/test.json
file_exist: /tmp/foo/test.json
afterfilename1: /tmp/foo/test.json
aftertype1: json
validtests: exitcode, file_exist

[Invalid test results]
headerdepth: 2
notes1: This is just to show what an invalid test looks like
cmd: ls -l /tmp/foo /does_not_exist
file_exist: /does_not_exist
validtests: exitcode, file_exist

[Adding more validtests]
headerdepth: 1
norun: true
notes1: The tests specified in 'validtests' are methods defined in the MDTest class
notes2: Any test specified just needs to exist as a method that begins with 'val_test_'. The current section is passed into each test method, so adding new definitions that tests rely on is rather easy.
